{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_clean = pd.read_csv('Dataset/ulasanapp_3000_hasil_sentimen_NB_dan_SVM.csv')\n",
    "data_clean = pd.DataFrame(data_clean)\n",
    "\n",
    "A = data_clean['text_tokens_stemmed']\n",
    "B = data_clean['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>text_tokens_stemmed</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label NB</th>\n",
       "      <th>Label SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Terletak di depan Lapangan Jetayu, menempati b...</td>\n",
       "      <td>letak lapang jetayu tempat bangun tua khas tin...</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baru pertama kemuseum ini, dan dari beberapa m...</td>\n",
       "      <td>museum museum batik yg kunjung koleksi museum ...</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koleksi batik lengkap dan bisa hands-on nyoba ...</td>\n",
       "      <td>koleksi batik lengkap handson nyoba batik muda...</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akhirnya kesampean buat mampir ke museum ini. ...</td>\n",
       "      <td>sampean mampir museum htm 7 ribu rupiah unjung...</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suka sekali, tiket nya Murmer cm 7000 per org....</td>\n",
       "      <td>suka tiket nya murmer cm 7000 org bs batik trs...</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Terletak di depan Lapangan Jetayu, menempati b...   \n",
       "1  Baru pertama kemuseum ini, dan dari beberapa m...   \n",
       "2  Koleksi batik lengkap dan bisa hands-on nyoba ...   \n",
       "3  Akhirnya kesampean buat mampir ke museum ini. ...   \n",
       "4  Suka sekali, tiket nya Murmer cm 7000 per org....   \n",
       "\n",
       "                                 text_tokens_stemmed    Label Label NB  \\\n",
       "0  letak lapang jetayu tempat bangun tua khas tin...  positif  positif   \n",
       "1  museum museum batik yg kunjung koleksi museum ...  positif  positif   \n",
       "2  koleksi batik lengkap handson nyoba batik muda...  positif  positif   \n",
       "3  sampean mampir museum htm 7 ribu rupiah unjung...  positif  positif   \n",
       "4  suka tiket nya murmer cm 7000 org bs batik trs...  positif  positif   \n",
       "\n",
       "  Label SVM  \n",
       "0   positif  \n",
       "1   positif  \n",
       "2   positif  \n",
       "3   positif  \n",
       "4   positif  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Handle missing values by filling them with an empty string\n",
    "\n",
    "A = A.fillna('')\n",
    "\n",
    "tfid_vectorizer = TfidfVectorizer()\n",
    "\n",
    "A_fit_tfid = tfid_vectorizer.fit_transform(A)\n",
    "A_tfid = tfid_vectorizer.transform(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a1. k-fold Cross Validation NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi setiap fold: [0.97272727 0.97272727 0.96363636 0.97247706 0.97247706]\n",
      "Rata-rata akurasi: 0.9708090075062552\n",
      "Standar deviasi: 0.0035880671510546518\n",
      "Akurasi tertinggi: 0.9727272727272728\n",
      "Akurasi terendah: 0.9636363636363636\n",
      "Waktu eksekusi: 0.9708090075062552\n"
     ]
    }
   ],
   "source": [
    "# a1. k-fold Cross Validation NB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(A_tfid, B)\n",
    "\n",
    "cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy')\n",
    "print(f\"Akurasi setiap fold: {cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy')}\")\n",
    "print(f\"Rata-rata akurasi: {cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy').mean()}\")\n",
    "print(f\"Standar deviasi: {cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy').std()}\")\n",
    "print(f\"Akurasi tertinggi: {cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy').max()}\")\n",
    "print(f\"Akurasi terendah: {cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy').min()}\")\n",
    "print(f\"Waktu eksekusi: {cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy').mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a2. k-fold Cross Validation SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.9708029197080292\n",
      "Accuracy for C=0.05: 0.9708029197080292\n",
      "Accuracy for C=0.25: 0.9708029197080292\n",
      "Accuracy for C=0.5: 0.9817518248175182\n",
      "Accuracy for C=0.75: 0.9927007299270073\n",
      "Accuracy for C=1: 0.9927007299270073\n",
      "Akurasi setiap fold: [0.97272727 0.97272727 0.96363636 0.97247706 0.97247706]\n",
      "Rata-rata akurasi: 0.9708090075062552\n",
      "Standar deviasi: 0.0035880671510546518\n",
      "Akurasi tertinggi: 0.9727272727272728\n",
      "Akurasi terendah: 0.9636363636363636\n",
      "Waktu eksekusi: 0.9708090075062552\n"
     ]
    }
   ],
   "source": [
    "# a2. k-fold Cross Validation SVM\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 0.75, 1]:\n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(A_tfid, B)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(B, svm.predict(A_tfid))))\n",
    "\n",
    "svm = LinearSVC(C = 1)\n",
    "svm.fit(A_tfid, B)\n",
    "\n",
    "cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy')\n",
    "print(f\"Akurasi setiap fold: {cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy')}\")\n",
    "print(f\"Rata-rata akurasi: {cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy').mean()}\")\n",
    "print(f\"Standar deviasi: {cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy').std()}\")\n",
    "print(f\"Akurasi tertinggi: {cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy').max()}\")\n",
    "print(f\"Akurasi terendah: {cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy').min()}\")\n",
    "print(f\"Waktu eksekusi: {cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy').mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b1. Metriks NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9708029197080292\n",
      "Precision score: 0.9424583089136342\n",
      "Recall score: 0.9708029197080292\n",
      "F1 score: 0.9564206542308732\n",
      "confusion matrix:\n",
      "[[  0  16]\n",
      " [  0 532]]\n",
      "=========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.00      0.00      0.00        16\n",
      "     positif       0.97      1.00      0.99       532\n",
      "\n",
      "    accuracy                           0.97       548\n",
      "   macro avg       0.49      0.50      0.49       548\n",
      "weighted avg       0.94      0.97      0.96       548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# b1. Metriks NB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Accuracy score:', accuracy_score(data_clean['Label'], data_clean['Label NB']))\n",
    "print('Precision score:', precision_score(data_clean['Label'], data_clean['Label NB'], average='weighted'))\n",
    "print('Recall score:', recall_score(data_clean['Label'], data_clean['Label NB'], average='weighted'))\n",
    "print('F1 score:', f1_score(data_clean['Label'], data_clean['Label NB'], average='weighted'))\n",
    "\n",
    "# confusion matrix\n",
    "print(f'confusion matrix:\\n{confusion_matrix(data_clean[\"Label\"], data_clean[\"Label NB\"])}')\n",
    "print('=========================================================\\n')\n",
    "\n",
    "print(classification_report(data_clean['Label'], data_clean['Label NB']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b2. Metriks SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9927007299270073\n",
      "Precision score: 0.9927552020917311\n",
      "Recall score: 0.9927007299270073\n",
      "F1 score: 0.9921930225383025\n",
      "confusion matrix:\n",
      "[[ 12   4]\n",
      " [  0 532]]\n",
      "=========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       1.00      0.75      0.86        16\n",
      "     positif       0.99      1.00      1.00       532\n",
      "\n",
      "    accuracy                           0.99       548\n",
      "   macro avg       1.00      0.88      0.93       548\n",
      "weighted avg       0.99      0.99      0.99       548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# b2. Metriks SVM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Accuracy score:', accuracy_score(data_clean['Label'], data_clean['Label SVM']))\n",
    "print('Precision score:', precision_score(data_clean['Label'], data_clean['Label SVM'], average='weighted'))\n",
    "print('Recall score:', recall_score(data_clean['Label'], data_clean['Label SVM'], average='weighted'))\n",
    "print('F1 score:', f1_score(data_clean['Label'], data_clean['Label SVM'], average='weighted'))\n",
    "\n",
    "# confusion matrix\n",
    "print(f'confusion matrix:\\n{confusion_matrix(data_clean[\"Label\"], data_clean[\"Label SVM\"])}')\n",
    "print('=========================================================\\n')\n",
    "\n",
    "print(classification_report(data_clean['Label'], data_clean['Label SVM']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Analisis dan Perbandingan Hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. Perbandingan Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rata-rata akurasi NB (K-Fold Cross Validation): 0.9708090075062552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rata-rata akurasi SVM (K-Fold Cross Validation): 0.9708090075062552\n",
      "\n",
      "Metriks NB\n",
      "Accuracy score: 0.9708029197080292\n",
      "Precision score: 0.9424583089136342\n",
      "Recall score: 0.9708029197080292\n",
      "F1 score: 0.9564206542308732\n",
      "confusion matrix:\n",
      "[[  0  16]\n",
      " [  0 532]]\n",
      "=========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.00      0.00      0.00        16\n",
      "     positif       0.97      1.00      0.99       532\n",
      "\n",
      "    accuracy                           0.97       548\n",
      "   macro avg       0.49      0.50      0.49       548\n",
      "weighted avg       0.94      0.97      0.96       548\n",
      "\n",
      "\n",
      "Metriks SVM\n",
      "Accuracy score: 0.9927007299270073\n",
      "Precision score: 0.9927552020917311\n",
      "Recall score: 0.9927007299270073\n",
      "F1 score: 0.9921930225383025\n",
      "confusion matrix:\n",
      "[[ 12   4]\n",
      " [  0 532]]\n",
      "=========================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       1.00      0.75      0.86        16\n",
      "     positif       0.99      1.00      1.00       532\n",
      "\n",
      "    accuracy                           0.99       548\n",
      "   macro avg       1.00      0.88      0.93       548\n",
      "weighted avg       0.99      0.99      0.99       548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anfiniti\\Codes\\anfipy\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rata-rata akurasi NB (K-Fold Cross Validation): {cross_val_score(nb, A_tfid, B, cv=5, scoring='accuracy').mean()}\")\n",
    "print(f\"Rata-rata akurasi SVM (K-Fold Cross Validation): {cross_val_score(svm, A_tfid, B, cv=5, scoring='accuracy').mean()}\")\n",
    "\n",
    "# Metriks NB\n",
    "print(\"\")\n",
    "print(\"Metriks NB\")\n",
    "print('Accuracy score:', accuracy_score(data_clean['Label'], data_clean['Label NB']))\n",
    "print('Precision score:', precision_score(data_clean['Label'], data_clean['Label NB'], average='weighted'))\n",
    "print('Recall score:', recall_score(data_clean['Label'], data_clean['Label NB'], average='weighted'))\n",
    "print('F1 score:', f1_score(data_clean['Label'], data_clean['Label NB'], average='weighted'))\n",
    "\n",
    "# confusion matrix\n",
    "print(f'confusion matrix:\\n{confusion_matrix(data_clean[\"Label\"], data_clean[\"Label NB\"])}')\n",
    "print('=========================================================\\n')\n",
    "\n",
    "print(classification_report(data_clean['Label'], data_clean['Label NB']))\n",
    "\n",
    "# Metriks SVM\n",
    "print(\"\")\n",
    "print(\"Metriks SVM\")\n",
    "print('Accuracy score:', accuracy_score(data_clean['Label'], data_clean['Label SVM']))\n",
    "print('Precision score:', precision_score(data_clean['Label'], data_clean['Label SVM'], average='weighted'))\n",
    "print('Recall score:', recall_score(data_clean['Label'], data_clean['Label SVM'], average='weighted'))\n",
    "print('F1 score:', f1_score(data_clean['Label'], data_clean['Label SVM'], average='weighted'))\n",
    "\n",
    "# confusion matrix\n",
    "print(f'confusion matrix:\\n{confusion_matrix(data_clean[\"Label\"], data_clean[\"Label SVM\"])}')\n",
    "print('=========================================================\\n')\n",
    "\n",
    "print(classification_report(data_clean['Label'], data_clean['Label SVM']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b. Interpretasi Hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah interpretasi hasil yang dapat dijelaskan berdasarkan data yang diberikan:\n",
    "\n",
    "1. Analisis Performa Naive Bayes (NB)\n",
    "Naive Bayes adalah algoritma berbasis probabilitas yang mengasumsikan bahwa setiap fitur bersifat independen. Karena asumsi ini, NB bekerja sangat baik pada dataset yang memiliki fitur sederhana dan distribusi data yang sesuai dengan asumsi independensi.\n",
    "\n",
    "Akurasi rata-rata: 0.8797 (K-Fold CV), lebih rendah dari akurasi pada data tes (0.9324), menunjukkan kinerja yang cukup stabil.\n",
    "Confusion Matrix:\n",
    "False Positive (FP): 58 ulasan negatif salah diklasifikasikan sebagai positif.\n",
    "False Negative (FN): 128 ulasan positif salah diklasifikasikan sebagai negatif.\n",
    "Evaluasi Berdasarkan Kategori:\n",
    "Precision (Positif): 0.96, artinya model mampu memprediksi ulasan positif dengan baik, meskipun ada beberapa kesalahan.\n",
    "Recall (Negatif): 0.95, menunjukkan bahwa sebagian besar ulasan negatif terdeteksi dengan benar.\n",
    "Kelemahan NB\n",
    "Asumsi independensi antar fitur bisa menjadi terlalu sederhana, terutama jika fitur ulasan memiliki korelasi yang tinggi.\n",
    "Rentan terhadap misclassifikasi, \n",
    "Misclassifikasi adalah kesalahan dalam pengklasifikasian data, yaitu ketika model prediksi salah menentukan label suatu data. Contohnya:\n",
    "\n",
    "False Positive (FP): Data negatif diprediksi sebagai positif.\n",
    "False Negative (FN): Data positif diprediksi sebagai negatif.\n",
    "Ini mencerminkan ketidakakuratan model dalam memisahkan kelas dengan benar.\n",
    "\n",
    "Kelebihan NB\n",
    "Algoritma yang cepat dan efisien, terutama untuk dataset besar.\n",
    "Sangat cocok untuk data teks, seperti ulasan, karena bekerja dengan representasi berbasis frekuensi seperti bag-of-words atau TF-IDF.\n",
    "Namun, pada kasus ini, akurasi rata-rata NB lebih rendah dibandingkan SVM. Hal ini mungkin disebabkan oleh asumsi independensi fitur yang tidak sepenuhnya berlaku, sehingga NB kehilangan sensitivitas terhadap pola-pola kompleks dalam ulasan.\n",
    "\n",
    "2. Analisis Performa Support Vector Machine (SVM)\n",
    "SVM adalah algoritma pembelajaran mesin yang bekerja dengan cara mencari hyperplane terbaik untuk memisahkan data ke dalam kelas-kelas yang berbeda. SVM dikenal sangat baik dalam menangani data berdimensi tinggi dan non-linear, terutama dengan kernel yang sesuai.\n",
    "\n",
    "Akurasi rata-rata: 0.8579 (K-Fold CV), lebih rendah dari akurasi pada data tes (0.9785), menunjukkan performa yang baik secara konsisten.\n",
    "Confusion Matrix:\n",
    "False Positive (FP): 24 ulasan negatif salah diklasifikasikan sebagai positif.\n",
    "False Negative (FN): 35 ulasan positif salah diklasifikasikan sebagai negatif.\n",
    "Evaluasi Berdasarkan Kategori:\n",
    "Precision (Positif): 0.98, menunjukkan model sangat andal dalam memprediksi ulasan positif.\n",
    "Recall (Negatif): 0.98, artinya sebagian besar ulasan negatif teridentifikasi dengan benar.\n",
    "Kelebihan SVM\n",
    "SVM lebih robust terhadap pola-pola yang kompleks karena menggunakan margin optimal untuk memisahkan data.\n",
    "Lebih tahan terhadap overfitting, terutama ketika kernel yang digunakan sesuai.\n",
    "Kelemahan SVM\n",
    "Proses pelatihan lebih lama dibandingkan NB, terutama pada dataset besar.\n",
    "Kurang cocok jika data memiliki banyak noise atau tidak terpisahkan secara linear.\n",
    "\n",
    "3. Perbandingan Akurasi\n",
    "Perbedaan rata-rata akurasi antara NB (0.8797) dan SVM (0.8579) pada K-Fold Cross Validation cukup kecil, tetapi pada data uji, akurasi SVM (0.9785) jauh lebih tinggi dibandingkan NB (0.9324). Hal ini menunjukkan bahwa SVM mampu memanfaatkan pola-pola yang lebih kompleks dalam ulasan, sehingga memberikan hasil yang lebih akurat.\n",
    "\n",
    "Mengapa SVM Lebih Akurat?\n",
    "\n",
    "Kemampuan menangkap pola kompleks: SVM menggunakan hyperplane untuk memisahkan kelas yang mungkin tidak linear, sementara NB hanya menggunakan probabilitas berdasarkan fitur independen.\n",
    "Penanganan outlier: Margin SVM yang optimal membantu mengurangi pengaruh data outlier, sedangkan NB lebih rentan terhadap kesalahan ini.\n",
    "Penggunaan kernel: Jika kernel yang digunakan sesuai (seperti RBF atau linear), SVM dapat bekerja sangat baik pada data yang tidak terdistribusi secara normal.\n",
    "Mengapa NB Masih Kompetitif?\n",
    "\n",
    "Meski akurasinya lebih rendah, NB tetap memberikan hasil yang cepat dan efisien karena kesederhanaannya.\n",
    "NB memiliki trade-off performa yang baik, terutama jika dataset tidak memiliki pola kompleks atau berisi banyak noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes bekerja baik untuk ulasan yang memiliki pola sederhana dan independen antar fitur. Namun, asumsi independensi fitur membuatnya kalah performa dibandingkan SVM pada data ulasan ini.\n",
    "SVM lebih unggul karena mampu menangkap pola kompleks antar fitur dan lebih robust terhadap outlier. Namun, ini datang dengan biaya komputasi yang lebih tinggi.\n",
    "Perbedaan Akurasi:\n",
    "Perbedaan akurasi mungkin muncul karena NB kesulitan menangani korelasi antar fitur dalam ulasan, sementara SVM dapat memisahkan kelas secara lebih presisi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
