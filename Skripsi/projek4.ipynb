{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file dataset_list_1.0.0.csv\n",
    "import pandas as pd\n",
    "\n",
    "kbbi = pd.read_csv('dataset_list_1.0.0.csv')\n",
    "kataa = kbbi['kata']\n",
    "# def filter_kata_kbbi(corpus):\n",
    "#     filtered_corpus = []\n",
    "#     for doc in corpus:\n",
    "#         # Pisahkan setiap kata, cek apakah ada di KBBI, dan gabungkan kembali\n",
    "#         filtered_doc = ' '.join([word for word in doc.split() if word.lower() in kbbi])\n",
    "#         filtered_corpus.append(filtered_doc)\n",
    "#     return filtered_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Lucu asli, kalo buka realtime trx harganya Rp....\n",
      "1     aplikasi REKU adalah dompet yang sama juga mut...\n",
      "2                                                    ok\n",
      "3     tambah mahal,, jarak jual dan belinya terlalu ...\n",
      "4     Aplikasi ini bagus untuk berdagang kripto, tam...\n",
      "                            ...                        \n",
      "95    Aplikasinya Mantap, segala fiturnya gampang di...\n",
      "96    Aplikasi yang bikin trading kripto jadi gampan...\n",
      "97     Aplikasi nya sangat mudah digunakan dan simple 👍\n",
      "98    Makin hari makin bagus, dan isilah ni koe'de u...\n",
      "99    Penjualan aset sungguh sangat lama sudah dari ...\n",
      "Name: content, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# baca data reku_selected3.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('reku_selected3.csv')\n",
    "corpus = df['content']\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baru', 'mau', 'coba', 'muda', 'mudahan', 'apk', 'nya', 'bagus']\n",
      "['Semoga', 'bisa', 'lebih', 'baik', 'lagi']\n",
      "['mudah', 'di', 'gunakan', 'sebagai', 'pemula']\n",
      "['menghibur', 'dan', 'bisa', 'mendapatkan', 'cuan']\n",
      "['baik']\n",
      "['bagus']\n",
      "['Sayangnya', 'gak', 'bisa', 'pake', 'keamanan', 'google', 'autentikasi']\n",
      "['Seharusnya', 'saya', 'tidak', 'memilih', 'apk', 'ini', 'saya', 'sungguh', 'kecewa']\n",
      "['2', 'di', 'dalam', 'aplikasinya', 'ada', 'kendala', 'pas', 'mau', 'minta', 'bantuan', 'sama', 'admin', 'tidak', 'bisa', 'chat', 'admin', 'tertutup']\n",
      "['sangat', 'bagus']\n",
      "['Bagus,ui', 'sederhana', 'mudah', 'dipahami', 'oleh', 'pemula.....saran', 'mohon', 'tambahkan', 'fitur', 'switch', 'antar', 'token', 'cripto', 'jd', 'tidak', 'perlu', 'jual', 'ke', 'idr', 'dulu']\n",
      "['Dari', 'awal', 'bikin', 'akun', 'mpe', 'saat', 'ini(selama', 'postingan', 'ga', 'dihapus', ')..Saya', 'gak', 'pernah', 'kasi', 'ijin/kuasa', 'ke', 'siapa', 'pun', ',Akun', 'ini', 'dibuat', 'ya', 'buat', 'saya', 'sendiri']\n",
      "['Gokil', 'next', 'tambahin', 'Reksadana', 'dan', 'emas', 'min']\n",
      "['Sangat', 'membantu', 'bagi', 'yang', 'menggunakan']\n",
      "['baik']\n",
      "['Aplikasi', 'yang', 'sangat', 'bagus.', 'Mudah', 'dan', 'adminya', 'fas', 'respon']\n",
      "['Jaringan', 'ton', 'knpa', 'tidak', 'bisa', 'digunakan', 'Sya', 'sudah', 'bli', 'mau', 'kitim', 'tidak', 'bisa']\n",
      "['ribet', 'amat', 'mau', 'ganti', 'nomor', 'aja']\n",
      "['bagus']\n",
      "['kalo', 'emang', 'cm', 'bs', '2', 'alamat', 'wallet,', 'alamat', 'lain', 'gausah', 'dimasukin', 'alasanya', 'cm', 'mendukung', 'trc', 'sm', 'erc', 'tapi', 'alamat', 'wallet', 'dimasukin', 'dikoin,', 'emang', 'mau', 'menjebak', 'orang', 'biar', 'salah,', 'saran', 'gw', 'gausah', 'pake', 'app', 'ini', 'mending', 'binance', 'atau', 'aplikasi', 'lain', 'yg', 'waras,', 'bukti', 'transaksi', 'semua', 'ada', 'gw', 'tapi', 'cs', 'bilang', 'duitnya', 'ilang', 'karna', 'alamat', 'walletny', 'yg', 'kekoin', 'langsung', 'gabisa', 'cm', 'erc', 'sama', 'trc,', 'fee', 'juga', 'ga', 'ngotak', 'gede', 'intinya', 'bermasalah']\n",
      "['baik']\n",
      "['Live', 'chat', 'nya', 'g', 'kebuka', 'parah', 'enak', 'yg', 'dulu', 'pass', 'respon', 'sekarang', 'agak', 'sulit']\n",
      "['bagus']\n",
      "['cukup', 'baik', 'semoga', 'bisa', 'menaikan', 'per', 'ekonomian', 'bagi', 'pengguna']\n",
      "['keren']\n",
      "['Sangat', 'bagus']\n",
      "['ok', 'mantap']\n",
      "['aplikasi', 'yg', 'bagus.transaksi', 'cepat', 'dan', 'mudah']\n"
     ]
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Membuat daftar stopwords dari Sastrawi\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()  # Mengambil daftar stopwords sebagai list\n",
    "\n",
    "# Inisialisasi list untuk menyimpan hasil\n",
    "# Proses filtering\n",
    "filtered_sentences = []\n",
    "\n",
    "for kalimat in corpus:\n",
    "    # Pecah kalimat menjadi kata-kata\n",
    "    kata_per_kalimat = kalimat.split()\n",
    "    for i in kata_per_kalimat:\n",
    "        a = 0\n",
    "        for j in kataa:\n",
    "            if i == j:\n",
    "                a = 1\n",
    "\n",
    "    if a == 1:\n",
    "        print(kata_per_kalimat)\n",
    "        a = 0\n",
    "    # Gabungkan kembali kata yang terfilter menjadi kalimat\n",
    "    # filtered_sentences.append(' '.join(kata_terfilter))\n",
    "\n",
    "# Tampilkan hasil filtering\n",
    "for kalimat in filtered_sentences:\n",
    "    print(kalimat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:1468\u001b[0m, in \u001b[0;36mCountVectorizer.get_feature_names_out\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \n\u001b[1;32m   1458\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;124;03m        Transformed feature names.\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1468\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m   1470\u001b[0m         [t \u001b[38;5;28;01mfor\u001b[39;00m t, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m1\u001b[39m))],\n\u001b[1;32m   1471\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m,\n\u001b[1;32m   1472\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:505\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_vocabulary()\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_:\n\u001b[0;32m--> 505\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary not fitted or provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
